{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8412\n",
      "For 0 error % = : 9.591836734693878\n",
      "For 1 error % = : 4.405286343612335\n",
      "For 2 error % = : 17.151162790697676\n",
      "For 3 error % = : 16.33663366336634\n",
      "For 4 error % = : 19.45010183299389\n",
      "For 5 error % = : 29.7085201793722\n",
      "For 6 error % = : 11.273486430062631\n",
      "For 7 error % = : 15.369649805447471\n",
      "For 8 error % = : 22.279260780287473\n",
      "For 9 error % = : 16.15460852329039\n",
      "Total Error: 15.880000000000006\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize(probs):\n",
    "    sum_probs = sum(probs)\n",
    "    if sum_probs == 0:          # smoothing is done here, if sum_of_probs = 0, means that one or more conditional probabilities are 0 \n",
    "        return normalize([1 for each in probs])\n",
    "    return [each/sum_probs for each in probs]\n",
    "\n",
    "def normalize_dict(d):\n",
    "    total = sum(d.values())\n",
    "    for each in d:\n",
    "        d[each] /= total\n",
    "    return d\n",
    "\n",
    "def train(train_data):\n",
    "    # returns a belief\n",
    "    prior = defaultdict(int)\n",
    "    counter = {i: {x: [0, 0] for x in range(10)} for i in range(784)}\n",
    "    for data in train_data:\n",
    "        data = convert_data(data)\n",
    "        label = data[0]\n",
    "        pixels = data[1:]\n",
    "        prior[label] += 1\n",
    "        for i in range(len(pixels)):\n",
    "            counter[i][label][pixels[i]] += 1\n",
    "    prior = normalize_dict(prior)\n",
    "    for i in range(784):\n",
    "        for x in range(10):\n",
    "            counter[i][x] = normalize(counter[i][x])\n",
    "    return prior, counter\n",
    "\n",
    "def argmax(l):\n",
    "    maximum = 0\n",
    "    result = None\n",
    "    for i in range(len(l)):\n",
    "        if l[i] > maximum:\n",
    "            maximum = l[i]\n",
    "            result = i\n",
    "    return result\n",
    "\n",
    "# returns int\n",
    "def predict(data):\n",
    "    global belief, prior\n",
    "    probs = [prior[x] for x in range(10)]\n",
    "    data = convert_data(data)\n",
    "    for i in range(len(data)):\n",
    "        for x in range(10):\n",
    "            probs[x] *= belief[i][x][data[i]]\n",
    "        probs = normalize(probs)\n",
    "    return argmax(probs)\n",
    "\n",
    "def convert_data(data):\n",
    "    return [data[0]] + [1 if each > 0 else 0 for each in data[1:]]\n",
    "\n",
    "\n",
    "def run_test(data):\n",
    "    no_of_rights,no_of_wrongs = 0,0\n",
    "    metrics = {i:[no_of_rights,no_of_wrongs] for i in range(10)}\n",
    "    right_output = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        row = data[i]\n",
    "        label = row[0]\n",
    "        pixels = row[1:]\n",
    "        prediction = predict(pixels)\n",
    "\n",
    "        if label==prediction:\n",
    "            metrics[label][0] += 1\n",
    "            right_output+=1\n",
    "        else:\n",
    "            metrics[label][1] += 1\n",
    "    acc = right_output/10000\n",
    "    return acc, metrics\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_train.csv\").read().strip().split(\"\\n\")]\n",
    "    prior, belief = train(train_data)\n",
    "    \n",
    "    test_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_test.csv\").read().strip().split(\"\\n\")]\n",
    "    accuracy,metrics = run_test(test_data)\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    for i in metrics:\n",
    "        print('For {} error % = : {}'.format(i, 100*(metrics[i][1]/sum(metrics[i]))))\n",
    "    print(\"Total Error: {}\".format(100*(1-accuracy)))\n",
    "    #print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1092\n",
      "For 0 error % = : 0.20408163265306123\n",
      "For 1 error % = : 99.8237885462555\n",
      "For 2 error % = : 97.96511627906976\n",
      "For 3 error % = : 99.20792079207921\n",
      "For 4 error % = : 99.59266802443992\n",
      "For 5 error % = : 99.55156950672645\n",
      "For 6 error % = : 99.68684759916492\n",
      "For 7 error % = : 93.09338521400778\n",
      "For 8 error % = : 100.0\n",
      "For 9 error % = : 99.90089197224975\n",
      "Total Error: 89.08\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize(probs):\n",
    "    sum_probs = sum(probs)\n",
    "    #if sum_probs == 0:          # smoothing is done here, if sum_of_probs = 0, means that one or more conditional probabilities are 0 \n",
    "        #return normalize([1 for each in probs])\n",
    "    return [each/sum_probs for each in probs]\n",
    "\n",
    "def normalize_dict(d):\n",
    "    total = sum(d.values())\n",
    "    for each in d:\n",
    "        d[each] /= total\n",
    "    return d\n",
    "\n",
    "def train(train_data):\n",
    "    # returns a belief\n",
    "    prior = defaultdict(int)\n",
    "    counter = {i: {x: [0, 0] for x in range(10)} for i in range(784)}\n",
    "    for data in train_data:\n",
    "        data = convert_data(data)\n",
    "        label = data[0]\n",
    "        pixels = data[1:]\n",
    "        prior[label] += 1\n",
    "        for i in range(len(pixels)):\n",
    "            counter[i][label][pixels[i]] += 1\n",
    "    prior = normalize_dict(prior)\n",
    "    #for i in range(784):\n",
    "        #for x in range(10):\n",
    "            #counter[i][x] = normalize(counter[i][x])\n",
    "    return prior, counter\n",
    "\n",
    "def argmax(l):\n",
    "    maximum = 0\n",
    "    result = None\n",
    "    for i in range(len(l)):\n",
    "        if l[i] > maximum:\n",
    "            maximum = l[i]\n",
    "            result = i\n",
    "    return result\n",
    "\n",
    "# returns int\n",
    "def predict(data):\n",
    "    global belief, prior\n",
    "    probs = [prior[x] for x in range(10)]\n",
    "    data = convert_data(data)\n",
    "    for i in range(len(data)):\n",
    "        for x in range(10):\n",
    "            probs[x] *= belief[i][x][data[i]]\n",
    "        #probs = normalize(probs)\n",
    "    return argmax(probs)\n",
    "\n",
    "def convert_data(data):\n",
    "    return [data[0]] + [1 if each > 0 else 0 for each in data[1:]]\n",
    "\n",
    "\n",
    "def run_test(data):\n",
    "    no_of_rights,no_of_wrongs = 0,0\n",
    "    metrics = {i:[no_of_rights,no_of_wrongs] for i in range(10)}\n",
    "    right_output = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        row = data[i]\n",
    "        label = row[0]\n",
    "        pixels = row[1:]\n",
    "        prediction = predict(pixels)\n",
    "\n",
    "        if label==prediction:\n",
    "            metrics[label][0] += 1\n",
    "            right_output+=1\n",
    "        else:\n",
    "            metrics[label][1] += 1\n",
    "    acc = right_output/10000\n",
    "    return acc, metrics\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_train.csv\").read().strip().split(\"\\n\")]\n",
    "    prior, belief = train(train_data)\n",
    "    \n",
    "    test_data = [list(map(int, line.strip().split(\",\"))) for line in open(\"mnist_test.csv\").read().strip().split(\"\\n\")]\n",
    "    accuracy,metrics = run_test(test_data)\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    for i in metrics:\n",
    "        print('For {} error % = : {}'.format(i, 100*metrics[i][1]/sum(metrics[i])))\n",
    "    #print(metrics)\n",
    "    print(\"Total Error: {}\".format((1-accuracy)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
